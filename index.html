<!doctype html>
<html lang="en">

<head>
	<meta charset="utf-8">

	<title>Massive Datenströme mit Kafka</title>

	<meta name="description" content="JAX 2016 - Kafka 101 - Massive Datenströme">
	<meta name="author" content="Frank Wisniewski &amp; Lars Pfannenschmidt">

	<meta name="apple-mobile-web-app-capable" content="yes" />
	<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

	<link rel="stylesheet" href="css/reveal.css">
	<link rel="stylesheet" href="css/theme/simple.css" id="theme">

	<!-- Code syntax highlighting -->
	<link rel="stylesheet" href="lib/css/zenburn.css">

	<!-- Printing and PDF exports -->
	<script>
	var link = document.createElement( 'link' );
	link.rel = 'stylesheet';
	link.type = 'text/css';
	link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
	document.getElementsByTagName( 'head' )[0].appendChild( link );
	</script>

	<!--[if lt IE 9]>
	<script src="lib/js/html5shiv.js"></script>
	<![endif]-->
</head>

<body>
	<div class="reveal">
		<!-- Any section element inside of this container is displayed as a slide -->
		<div class="slides">
			<section>
				<small><h3>JAX 2016</h3></small>
				<h1>Kafka 101 Massive Datenströme</h1>
				<p>
					Frank Wisniewski - <a href="http://twitter.com/ultraknackig" target="_blank">@ultraknackig</a><br/>
					Lars Pfannenschmidt - <a href="http://twitter.com/leastangle" target="_blank">@leastangle</a>
				</p>
				<aside class="notes">
					RabbitMQ? ActiveMQ? Verbrechen wie JMS? Und Kafka...?<br/>
					<b>verteilter, partitionierender, replizierender</b> Service f&uuml;r Datenstr&ouml;me.
				</aside>
			</section>

			<section>
				<h2>$ whoami</h2>
				<h4>Frank Wisniewski</h4>
				<ul>
					<li>Futsal playing Engineer <a href="http://twitter.com/Intuit" target="_blank">@Intuit</a></li>
					<li>Event-Driven &amp; Real Time Applications</li>
					<li><a href="https://twitter.com/ultraknackig">@ultraknackig</a></li>
				</ul>
				<p/>
				<h4>Lars Pfannenschmidt</h4>
				<ul>
					<li>Real Time Data Products <a href="http://twitter.com/Intuit" target="_blank">@Intuit</a></li>
					<li>Founder of <a href="https://twitter.com/mobilecgn">@mobilecgn</a> User Group</li>
					<li><a href="https://twitter.com/leastangle">@leastangle</a></li>
				</ul>
			</section>

			<section>
				<h2>$ ls -al</h2>
				<ul>
					<li class="fragment">Motivation</li>
					<div class="fragment">
						<li>Concepts</li>
						<ul>
							<li>Topics &amp; Partitions</li>
							<li>Offset Management</li>
							<li>Log Compaction</li>
							<li>Quotas</li>
						</ul>
					</div>
					<div class="fragment">
						<li>Example</li>
						<ul>
							<li>Producer</li>
							<li>Consumer</li>
						</ul>
					</div>
					<li class="fragment">Performance</li>
					<li class="fragment">Operations</li>
					<li class="fragment">Summary</li>
				</ul>
			</section>

			<section>
				<section data-background="img/motivation.jpg">
					<h1>Motivation</h1>
					<aside class="notes">
						"WTF! Y? gibt doch schon messaging was super und toll auch ist...", interns Projekt LinkedIn; einheitliche Plattform zur Verarbeitung von großen Datenströmen;
					</aside>
				</section>
				<section>
					<h2>Chaos</h2>
					<img src="img/datapipeline_complex.jpg"/>
					<small><a href="http://linkd.in/199iMwY">„The Log: What every software engineer should know about real­time data's unifying abstraction“</a> by Jay Kreps</small>
					<aside class="notes">
						uni-/bidirektionale Abhaenigkeiten (Daten) kreuz und quer; Unwartbar
					</aside>
				</section>
				<section>
					<h2>Order</h2>
					<img src="img/datapipeline_simple.jpg"/>
					<small><a href="http://linkd.in/199iMwY">„The Log: What every software engineer should know about real­time data's unifying abstraction“</a> by Jay Kreps</small>
					<aside class="notes">
						entkoppeltes Nachrichtensystem; klassisches funktionierte nicht; wurde LinkedIn's “zentralen Nervensystem”
					</aside>
				</section>
				<section>
					<h2>Required Guarantees</h2>
					<ul>
						<li class="fragment">low latency</li>
						<li class="fragment">scalable</li>
						<li class="fragment">fault-tolerant</li>
					</ul>
					<small><blockquote cite="https://www.linkedin.com/pulse/20141106180403-2945786-announcing-confluent-a-company-for-apache-kafka-and-realtime-data">"None were built like a modern distributed system that you could safely dump all the data of a growing company into and scale along with your needs."</blockquote></small>
					<aside class="notes">
						Kernanforderungen: <b>Latenz, Skalierbarkeit, Fehlertoleranz &amp; Verfügbarkeit</b>
						<ul>
							<li>low latency enough to satisfy our realtime data flows</li>
							<li>scalable enough to handle very high volume log and event data</li>
							<li>fault-tolerant enough for critical data delivery -> durable persistence</li>
						</ul>
					</aside>
				</section>
			</section>

			<section>
				<section data-background="img/concepts.jpg">
					<h1>Concepts</h1>
				</section>
				<section>
					<h2>Overview</h2>
					<img width="65%" src="img/overview.png"/>
					<small>Topological Overview according to <a href="http://kafka.apache.org/documentation.html">Kafka documentation</a></small>
				</section>
				<section>
					<h2>Topics &amp; Partitions</h2>
					<img src="img/topic.png"/>
					<small>Anatomy of a topic according to <a href="http://kafka.apache.org/documentation.html">Kafka documentation</a></small>
					<aside class="notes">
						Nachrichten &rarr; Topic; <br/>durable;<br/> n Partitionen und Knoten verteilt;<br/> sequentiell;<br/> Offset/Order pro partition;<br/> Replikation; Retention;<br/>
						<b>Obacht:</b> Partitionen Nachtr&auml;gliches &Auml;ndern :(
					</aside>
				</section>
				<section>
					<h2>Guarantees</h2>
					<ul>
						<li>Messages sent to a partition will be appended in the order they are seen</li>
						<li>Consumer see messages in the order they are stored in the log</li>
						<li>Kafka will tolerate up to <code>n-1</code> server failures for a topic with replication factor <code>n</code></li>
					</ul>
				</section>
				<section>
					<h2>Log Compaction</h2>
					<img width="65%" src="img/log_compaction.png"/>
					<small>Log compaction according to <a href="http://kafka.apache.org/documentation.html">Kafka documentation</a></small>
					<aside class="notes">
						Compression nicht m&ouml;glich
					</aside>
				</section>
				<section>
					<h2>Quotas</h2>
					<ul>
						<li class="fragment">
							Set Broker default (in bytes/sec)
							<pre><code data-trim class="bash">
quota.producer.default=10485760
quota.consumer.default=10485760
							</code></pre>
						</li>
						<li class="fragment">
							 Custom quotas per client
							<pre><code data-trim class="bash">
$ kafka-configs.sh --zookeeper 127.0.0.1:2181 --alter
--add-config 'producer_byte_rate=4096,consumer_byte_rate=4096'
--entity-name client123 --entity-type clients
							</code></pre>
						</li>
					</ul>
					<div>
						<small class="fragment">Don't forget to set the client id :)</small>
					</div>
					<aside class="notes">
						Shared Infrastructure, bad clients, DoS. Quote is per Broker, not Cluster!
					</aside>
				</section>
			</section>

			<section>
				<section data-background="img/example.jpg">
					<!--<h1>Example</h1>-->
					<p/>
				</section>
				<section>
					<h2>Java Producer</h2>
					<pre class="fragment"><code data-trim class="java">
public class News {
    public final UUID id;
    public final String author, title, body;
...
}
					</code></pre>
					<pre class="fragment"><code data-trim class="java">
Properties config = new Properties();
config.put(ProducerConfig.CLIENT_ID_CONFIG, "NewsProducer");
config.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, broker);
config.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
config.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, NewsSerializer.class.getName());

KafkaProducer&lt;String, News&gt; producer = new KafkaProducer&lt;&gt;(config);
					</code></pre>
					<pre class="fragment"><code data-trim class="java">
public RecordMetadata send(News news) throws ExecutionException, InterruptedException {
    ProducerRecord&lt;String, News&gt; record = new ProducerRecord&lt;&gt;(topic, news.id.toString(), news);
    Future&lt;RecordMetadata&gt; recordMetadataFuture = this.producer.send(record);
    return recordMetadataFuture.get();
}
					</code></pre>
					<aside class="notes">
						SourceCode zu klein? Folien bereitgestellt!<br>
						Kafka &rarr; byte[]<br> Domäne benötigt eigene <b>De-/Serializer</b>
					</aside>
				</section>

				<section>
					<h2>Message Distribution</h2>
					Message routing to target partition via <code>ProducerRecord</code><br/><br/>
					<ul>
						<li class="fragment">
							Round Robin
							<pre><code data-trim class="java">
								ProducerRecord(String topic, V value);
							</code></pre>
						</li>
						<li class="fragment">
							Via <code>key</code> hash (murmur2)
							<pre><code data-trim class="java">
								ProducerRecord(String topic, K key, V value);
							</code></pre>
						</li>
						<li class="fragment" style="width:110%">
							Via specific partition
							<pre><code data-trim class="java">
								ProducerRecord(String topic, Integer partition, K key, V value);
							</code></pre>
						</li>
					</ul>
					<aside class="notes">
						<b>Erinnerung:</b> Reihenfolge pro Partititon garantiert;<br> LogCompaction ohne Key?
					</aside>
				</section>

				<section>
					<h2>Consumer Lifecycle</h2>
					<ul>
						<li class="fragment">Topic Subscription &amp; Partition Assignment</li>
						<li class="fragment">Message Polling</li>
						<li class="fragment">Partition Rebalance Handling</li>
						<li class="fragment">Offset Management</li>
						<li class="fragment">Shutdown</li>
					</ul>
					<aside class="notes">
						<ul>
							<li>Partition Assignment</li>
							<li>Poll
								<ul><li>#threads</li></ul>
							</li>
							<li>Rebalance
								<ul><li>clean up &amp; save state before losing ownership on partition</li></ul>
							</li>
							<li>Offset</li>
							<li>Shutdown</li>
						</ul>
					</aside>
				</section>
				<section>
					<h2>Consumer Groups</h2>
					<img src="img/consumer_grouping.png"/>
					<small>“Kafka 101 - Massive Datenströme mit Apache Kafka” by Pfannenschmidt and Wisniewski, JavaMagazin 08.2015, p. 38</small>
					<aside class="notes">
						<ul>
							<li>Dynamically add &amp; remove consumers on the fly
								<br />&#8594; scalability &amp; availability
								<br />&#8594; triggers rebalance
								<br />&#8594; short window of unavailability
								<br />&#8594; state loss
							</li>
							<li>Membership maintained via heartbeats to <b>one</b> broker (<i>group coordinator</i>)</li>
							<li>Strategien zum konsumieren: <b>links</b> Queue; <b>rechts</b> Topic/publish-subscribe</li>
							<ul>
								<li><b>Topic A:</b>Nachrichten <i>entweder</i> von A0 <i>oder</i> A1</li>
								<li><b>Topic B:</b>Nachrichten <i>sowohl</i> von B0 <i>als auch</i> von einem Consumer aus Gruppe C empfangen</li>
							</ul>
						</li>
					</ul>
					</aside>
				</section>
				<section>
					<h2>Partition Assignment</h2>
					<img width="65%" src="img/partition_assignment_1.png"/>
					<aside class="notes">
						<li>#Consumer &gt; #Partitionen &rarr; &uuml;bersch&uuml;ssigen Consumer erhalten keine Nachrichten
					</aside>
				</section>
				<section>
					<h2>Partition Assignment</h2>
					<img width="65%" src="img/partition_assignment_2.png"/>
					<small>Assignment algorithm configurable via consumer parameter <code data-trim class="java">partition.assignment.strategy</code></small>
					<aside class="notes">
						#Consumer &lt; #Partitionen &rarr; Consumer bekommen Nachrichten von mehreren Partitionen.
					</aside>
				</section>

				<section>
					<h2>Java Consumer</h2>
					<pre class="fragment"><code data-trim class="java">
public SimpleConsumer(String bootstrapServers, String groupId, NewsConsumer consumer) {
    this.bootstrapServers = bootstrapServers;
    ...
    this.name = String.format("%s[%s]", groupId, CONSUMER_SEQUENCE.getAndIncrement());
}
					</code></pre>
					<pre class="fragment"><code data-trim class="java">
public interface NewsConsumer&lt;News&gt; {
	void consume(News message);
	String getTopic();
}
					</code></pre>
					<pre class="fragment"><code data-trim class="java">
private Consumer&lt;String, News&gt; createConsumer() {
    Properties props = new Properties();
    props.put(BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);  // list of broker nodes
    props.put(GROUP_ID_CONFIG, groupId);                    // identifies consumer group
    props.put(AUTO_OFFSET_RESET_CONFIG, "earliest");        // fallback beahaviour on invalid offset
    props.put(ENABLE_AUTO_COMMIT_CONFIG, true);             // turn on auto-commit (default)
    props.put(KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
    props.put(VALUE_DESERIALIZER_CLASS_CONFIG, NewsDeserializer.class);
    props.put(CLIENT_ID_CONFIG, getClientId());

    return new KafkaConsumer&lt;&gt;(props);
}
					</code></pre>
					<aside class="notes">
						<ul>
							<li>3 APIs
								<ul>
									<li><b>High Level Consumer API</b> lagert das Verwalten des Offset nach ZooKeeper oder Kafka aus</li>
									<li><b>SimpleConsumer</b> &uuml;berl&auml;sst dies der Consumer-Implementierung</li>
									<li>Hier: neue API 0.9</li>
								</ul>
								<li>new KafkaConsumer&lt;&gt;(props); schmeißt unchecked Exception.</li>
						</ul>

					</aside>
				</section>

				<section>
					<h2>Java Consumer run()</h2>
					<pre class="fragment"><code data-trim class="java">
@Override
public void run() {
    try {
        Thread.currentThread().setName(name);
        consumer = createConsumer();
        consumer.subscribe(Arrays.asList(newsConsumer.getTopic()));
        logger.info("Started consumer thread {}", name);
        while (running) {
            ConsumerRecords&lt;String, News&gt; records = consumer.poll(POLLING_TIMEOUT_MS);
            records.forEach(record -> relayMessage(record));
        }
    } catch (Exception ex) {
        logger.error("Started consumer thread", ex);
    } finally {
        close();
    }
}
					</code></pre>
					<pre class="fragment"><code data-trim class="java">
private void relayMessage(ConsumerRecord&lt;String, News&gt; kafkaRecord) {
    logger.info("Received message with key '{}' and offset '{}' on partition '{}' for topic '{}'",
        kafkaRecord.key(), kafkaRecord.offset(), kafkaRecord.partition(), kafkaRecord.topic());
    newsConsumer.consume(kafkaRecord.value());
}
					</code></pre>
					<aside class="notes">
						poll ist nicht thread-safe: nebenläufiger Aufruf schmeißt Exception
					</aside>
				</section>

				<section>
					<h2>Consumer Pool</h2>
					<pre class="fragment"><code data-trim class="java">
public void start(List&lt;NewsConsumer&gt; newsConsumers) {
    pool = Executors.newFixedThreadPool(newsConsumers.size());

    for (NewsConsumer newsConsumer : newsConsumers) {
        SimpleConsumer consumer = new SimpleConsumer(bootstrapServers, groupId, newsConsumer);
        consumers.add(consumer);
        pool.submit(consumer);
    }
}
					</code></pre>
					<pre class="fragment"><code data-trim class="java">
public void stop() {
    consumers.forEach(SimpleConsumer::stop);
    if (pool != null) {
        pool.shutdown();
    }
    logger.info("Shutdown all {} threads of consumer pool", consumers.size());
    consumers.clear();
}
					</code></pre>
					<small class="fragment">Full Code Example: <a href="https://github.com/datanerds-io/java-news-feed">https://github.com/datanerds-io/java-news-feed</a></small>
					<aside class="notes">
					</aside>
				</section>
			</section>

			<section>
				<section data-background="img/performance.jpg">
					<h1>Performance</h1>
					<aside class="notes">
						16 Mrd Nachrichten am Tag.<br>Limit REST, nicht Kafka.<br>Das ganze Setup 200.000TPS
					</aside>
				</section>
				<section>
					<h2>What makes Kafka fast?</h2>
					<blockquote cite="http://kafka.apache.org/documentation.html#maximizingefficiency">"[Designed] to make consumption as cheap as possible"</blockquote>
					<aside class="notes">
						Teure Probleme beim Messaging:<br/>
						Exactly once &rarr; At least once<br/>
						Order &rarr; Partitions<br/>
						ActiveMQ cross consumption #fail<br/>
						Rein Z&uuml;f&auml;llig Messaging<br/>
					</aside>
				</section>
				<section>
					<h2>What makes Kafka fast?</h2>
					<div class="fragment">
					<h4>Fast Writes:</h4>
					<ul>
						<li>linear writes</li>
						<li>all writes go to OS pagecache</li>
					</ul>
					<p/>
					</div>
					<div class="fragment">
					<h4>Fast Reads:</h4>
					<ul>
						<li>linear reads</li>
						<li>direct data transport from <br>pagecache to socket* via <code><a href="http://man7.org/linux/man-pages/man2/sendfile.2.html" target="blank">sendfile()</a></code></li>
					</ul>
					<br><br>
					</div>
					<div class="fragment">
					<h3>Combined &#8594; Fast!</h3>
					<p>
						<small>* Consumer without lag get messages from pagecache!<br/>
							More Details: <a href="http://kafka.apache.org/documentation.html#persistence" target="_blank">http://kafka.apache.org/documentation.html#persistence</a>
						</small>
					</p>
					</div>
					<aside class="notes">
						Durable queues bei den klassikern "langsam"<br>
						linear writes outperform random writes by far!<br>
						OS optimiert: read-ahead/write-behind<br>
						ACM Artikel: "random access to memory is typically slower than sequential access to disk!"
					</aside>
				</section>
				<section>
					<h2>sendfile()?</h2>
					<img src="img/traditional data copy vs sendfile.png"/>
					<small>Efficient data transfer according to  <a href="http://www.ibm.com/developerworks/library/j-zerocopy/">http://www.ibm.com/developerworks/library/j-zerocopy/</a></small>
					<aside class="notes">
						links ohne, rechts mit <code>sendfile()</code><br>
						<code>FileChannel.transferTo()</code>, falls JVM/OS unterst&uuml;tzt &rarr; sendfile().
					</aside>
				</section>
			</section>
		</section>
		<section>
			<section data-background="img/operations.jpg">
				<h1>Operations</h1>
				<aside class="notes">
				</aside>
			</section>
			<section>
				<h2>Broker</h2>
				<ul>
					<li class="fragment"><code>-XX:+UseG1GC</code></li>
					<li class="fragment"><code>default.replication.factor=3</code></li>
					<li class="fragment"><code>min.insync.replicas=2 (ISR)</code></li>
					<li class="fragment"><code>unclean.leader.election.enable=false</code></li>
				</ul>
				<aside class="notes">
					Jepsen? Kyle Kingsbury
				</aside>
			</section>
			<section>
				<h2>Producer</h2>
				<ul>
					<li class="fragment"><code>acks=all</code></li>
					<li class="fragment"><code>block.on.buffer.full=true</code></li>
					<li class="fragment"><code>retries=Integer.MAX_VALUE</code></li>
					<li class="fragment"><code>max.in.flight.requests.per.connection=1</code></li>
					<li class="fragment"><code>KafkaProducer.close()</code></li>
				</ul>
				<h2 class="fragment">Consumer</h2>
				<ul>
					<li class="fragment"><code>enable.auto.commit=false</code></li>
				</ul>
				<aside class="notes">
					In Flight -> Frank Nachricht 1 überholt 2<br/>
					Commit NACH erfolgreicher verarbeitung
				</aside>
			</section>
		</section>
		<section>
			<section data-background="img/summary.jpg">
				<h1>Summary</h1>
			</section>
			<section>
				<h2>Key Features &amp; Facts</h2>
				<ul>
					<li class="fragment"><b>Commit Log</b>&emsp;&emsp;Topics, Partitioning, Log Compaction, Compression &amp; Offset Management</li>
					<li class="fragment"><b>Real-time</b>&emsp;&emsp;&emsp;High-Throughput &amp; Low-Latency</li>
					<li class="fragment"><b>Persistence</b>&emsp;&emsp;Scalable, centralized &amp; replicated storage</li>
				</ul>
			</section>
			<section>
				<h2>Related</h2>
				<ul>
					<li class="fragment"><b>Clients</b>&emsp;&emsp;&emsp;Scala, Java, Python, Go, Perl, Erlang etc.</li>
					<li class="fragment"><b>Integration</b>&emsp;Spark, Storm, Samza, Hadoop, ElasticSearch, Logstash, Hive etc.</li>
					<li class="fragment"><b>Confluent Platform</b>&emsp;Schema Registry, REST Proxy &amp; Camus</li>
					<li class="fragment"><b>Kafka Streams</b>&emsp;&emsp;&emsp;Stream processing library vs. frameworks</li>
				</ul>
			</section>
		</section>
		<section>
			<p>
				<a href="http://datanerds.io" target="_blank"><img width="150" style="border: 0px; background: none; box-shadow: none;" src="img/datanerds.png"/></a><br/>
			</p>
			<h1>Thank You!</h1>
			<p>
				<a href="http://twitter.com/Intuit" target="_blank">@Intuit</a><br/>
				<a href="http://datanerds.io" target="_blank">datanerds.io</a><br/>
				Frank Wisniewski - <a href="http://twitter.com/ultraknackig" target="_blank">@ultraknackig</a><br/>
				Lars Pfannenschmidt - <a href="http://twitter.com/leastangle" target="_blank">@leastangle</a><br/>
			</p>
		</section>
		<section>
			<div>Attributions:</div><p/>
			<small><a href="https://flic.kr/p/81Z1JA">Angry Girl</a> by Steven Depolo - Some rights reserved <a href="https://creativecommons.org/licenses/by/2.0/">CC BY 2.0</a></small>
			<small><a href="https://flic.kr/p/9aQ5rN">Sometimes, we do puzzles...</a> by Jameel Winter - Some rights reserved <a href="https://creativecommons.org/licenses/by/2.0/">CC BY 2.0</a></small>
			<small><a href="https://flic.kr/p/i9tDQY">Programming With Biscuits</a> by fdecomite - Some rights reserved <a href="https://creativecommons.org/licenses/by/2.0/">CC BY 2.0</a></small>
			<small><a href="https://flic.kr/p/asbhA6">School Time Jet Bus</a> by Doug Wertman - Some rights reserved <a href="https://creativecommons.org/licenses/by/2.0/">CC BY 2.0</a></small>
			<small><a href="https://flic.kr/p/bEEdn3">Cockpit </a> by Roger Schultz - Some rights reserved <a href="https://creativecommons.org/licenses/by/2.0/">CC BY 2.0</a></small>
			<small><a href="https://flic.kr/p/dHPGVp">Overflowing </a> by Matti Mattila - Some rights reserved <a href="https://creativecommons.org/licenses/by/2.0/">CC BY 2.0</a></small>
		</section>
	</div>
</div>

<script src="lib/js/head.min.js"></script>
<script src="js/reveal.js"></script>

<script>

// Full list of configuration options available at:
// https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({
	controls: true,
	progress: true,
	history: true,
	center: true,
	width: 1024,
	height: 768,
	margin: 0.1,
	minScale: 0.75,
	maxScale: 1.2,
	slideNumber: 'c/t',

	transition: 'slide', // none/fade/slide/convex/concave/zoom

	// Optional reveal.js plugins
	dependencies: [
		{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
		{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
		{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
		{ src: 'plugin/highlight/highlight.js', async: true, condition: function() { return !!document.querySelector( 'pre code' ); }, callback: function() { hljs.initHighlightingOnLoad(); } },
		{ src: 'plugin/zoom-js/zoom.js', async: true },
		{ src: 'plugin/notes/notes.js', async: true }
	]
});

</script>
</body>
</html>
